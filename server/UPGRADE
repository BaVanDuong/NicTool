
To upgrade NicTool to v2.10, the following steps should be taken:

1. shut down export processes (stop DNS server updates)
     # $local/etc/rc.d/svscan stop
            or
     # service svscan stop  (or: initctl stop svscan)

2. shut down web/nictool server (prevent DB changes)
     $ $local/etc/rc.d/apache22 stop
            or
     # service httpd stop

3. install NicTool client & server
     http://www.nictool.com/docs/client/install.shtml
     http://www.nictool.com/docs/server/install.shtml

4. run the database migration scripts
     # cd /usr/local/nictool/server
     # sql/upgrade.pl

5. start up web server & validate

6. install new export dependencies
    Time::TAI64
    Params::Validate
    DBIx::Simple

7. create new exports
    # cd /usr/local/nictool
    # mkdir ns1.example.com
    # cd ns1.example.com
    # ln -s ../server/bin/nt_export.pl .
    # ./nt_export.pl -nsid N  (run without a NSID to see a list)

After a successful export, this last step will leave behind:
  1. 'run' file
  2. data directory with the exported data file(s).
  3. if NS type is tinydns, it will also leave behind a Makefile, customized for building data.cdb and rsyncing it to the right place. If the settings are incorrect, just edit the Makefile. To customize the export (to rsync to multiple servers, or different servers, or via private IPs, or whatever), edit the Makefile.

    # ./run  (test the run file)

Since this is an upgrade, presumably you already have an existing run file, export users, and ssh keys all set up. If so, this should "just work."

    # ln -s /usr/local/nictool/ns1.example.com /service/

Tell svscan to start up this daemon.


    SIGNIFICANT DIFFERENCES FROM PRE-v2.10 EXPORT SCRIPT

SPEED: The old export scripts used a c++ application to dump the data from MySQL to the data file. This set of scripts is pure perl. I spent very little time optimizing these exports for speed. Most NicTool users have hundreds or thousands of domains. And premature optimization is the root of all evil. My DB exports complete in under a second. If you have hundreds of thousands of domains, you may want to test the performance of exports with your data set before upgrading. There is no sql/downgrade script.

DATA FILE:

I discovered these differences by doing a diff on a 'data' file exported using the old export scripts to one generated by the new export scripts. I suggest you do the same. Pipe them both through sort first, and then diff or diff -y reveals all.

* A zone with no defined resource records now publishes SOA records. Previously it did not.

* Spaces in address fields are now character encoded ( ' ' -> '\040' ) in the tinydns data file

* SRV records are exported as generic tinydns. The primary reason for this is
  that now we don't require the tinydns patch to publish SRV records. Here's a before/after:

    S_caldav._tcp.simerson.net::calendars.simerson.net.:443:100:5:3600::
    :_caldav._tcp.simerson.net:33:\000\005\000\144\001\273\011calendars\010simerson\003net\000:3600::

